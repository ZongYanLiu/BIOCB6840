{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the total length of each transcript\n",
    "transcript_lengths = {}\n",
    "\n",
    "# Open the bed file for reading\n",
    "with open('/workdir/zl843/translation-start-site/Arabidopsis_thaliana.TAIR10.57.gff3.5-UTR', 'r') as bed_file:\n",
    "    for line in bed_file:\n",
    "        parts = line.strip().split(' ')\n",
    "        transcript_id = parts[0]\n",
    "        transcript_length = int(parts[4])\n",
    "        \n",
    "        # Check if the transcript_id is already in the dictionary\n",
    "        if transcript_id in transcript_lengths:\n",
    "            # If it is, add the current length to the existing total\n",
    "            transcript_lengths[transcript_id] += transcript_length\n",
    "        else:\n",
    "            # If it's not, initialize the total length\n",
    "            transcript_lengths[transcript_id] = transcript_length\n",
    "\n",
    "# Create a dictionary to store the sequences based on transcript IDs\n",
    "transcript_sequences = {}\n",
    "\n",
    "# Open the FASTA file for reading\n",
    "with open('/workdir/zl843/translation-start-site/Arabidopsis_thaliana.TAIR10.cdna.all.fa', 'r') as fasta_file:\n",
    "    current_transcript_id = None\n",
    "    sequence = ''\n",
    "    \n",
    "    for line in fasta_file:\n",
    "        if line.startswith('>'):\n",
    "            # Store the previous transcript's sequence if available\n",
    "            if current_transcript_id is not None:\n",
    "                transcript_sequences[current_transcript_id] = sequence\n",
    "                \n",
    "            # Update the current transcript ID\n",
    "            current_transcript_id = line[1:].split()[0]\n",
    "            sequence = ''\n",
    "        else:\n",
    "            sequence += line.strip()\n",
    "\n",
    "    # Store the last transcript's sequence\n",
    "    transcript_sequences[current_transcript_id] = sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the sequence as FASTA file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output file for writing the extracted sequences\n",
    "with open('UTR_output.fasta', 'w') as output_file:\n",
    "    for transcript_id, total_length in transcript_lengths.items():\n",
    "        if transcript_id in transcript_sequences:\n",
    "            sequence = transcript_sequences[transcript_id][:total_length]\n",
    "            output_file.write(f\">{transcript_id}\\n{sequence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search the ATG in the 5'-UTR site**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to search for \"ATG\" in 3-mers\n",
    "def find_atg_in_sequence(sequence, sequence_id):\n",
    "    atg_positions = []\n",
    "    sequence = sequence[::-1]  # Reverse the sequence for scanning from the end\n",
    "    for i in range(0, len(sequence) - 2, 3):\n",
    "        if sequence[i:i + 3] == \"GTA\":\n",
    "            atg_positions.append(len(sequence) - i - 3)  # Calculate position from the end\n",
    "    if atg_positions:\n",
    "        return (sequence_id, atg_positions)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Read the FASTA file and search for \"ATG\"\n",
    "fasta_file = \"/workdir/zl843/translation-start-site/UTR_output.fasta\"\n",
    "results = []\n",
    "\n",
    "with open(fasta_file, \"r\") as file:\n",
    "    sequence_id = None\n",
    "    sequence = \"\"\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\">\"):\n",
    "            if sequence_id is not None:\n",
    "                result = find_atg_in_sequence(sequence, sequence_id)\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "            sequence_id = line[1:]\n",
    "            sequence = \"\"\n",
    "        else:\n",
    "            sequence += line\n",
    "\n",
    "# Check the last sequence in the file\n",
    "if sequence_id is not None:\n",
    "    result = find_atg_in_sequence(sequence, sequence_id)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# Write the results to a file\n",
    "output_file = \"atg_positions.txt\"\n",
    "with open(output_file, \"w\") as output:\n",
    "    for result in results:\n",
    "        sequence_id, positions = result\n",
    "        for position in positions:\n",
    "            output.write(f\"{sequence_id}\\t{position}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output the ATG start site in the 5'-UTR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data written to /workdir/zl843/translation-start-site/ATG_in_5-UTR.bed\n"
     ]
    }
   ],
   "source": [
    "# Read the first file and store the data in a dictionary\n",
    "bed_file = \"/workdir/zl843/translation-start-site/Arabidopsis_thaliana.TAIR10.57.gff3.mRNA.bed\"\n",
    "transcripts = {}\n",
    "with open(bed_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        chrom, start, end, strand, transcript_id = parts\n",
    "        transcripts[transcript_id] = (chrom, int(start), int(end), strand)\n",
    "\n",
    "# Read the second file and update the positions\n",
    "length_file = \"/workdir/zl843/translation-start-site/atg_positions.txt\"\n",
    "output = []\n",
    "with open(length_file, 'r') as f:\n",
    "    for line in f:\n",
    "        transcript_id, length = line.strip().split('\\t')\n",
    "        length = int(length)\n",
    "        chrom, start, end, strand = transcripts[transcript_id]\n",
    "\n",
    "        if strand == '+':\n",
    "            start = start + length - 1\n",
    "        else:\n",
    "            end = end - length\n",
    "\n",
    "        output.append((chrom, start, end, transcript_id, \".\", strand))\n",
    "\n",
    "# Write the updated data to a new file\n",
    "output_file = \"/workdir/zl843/translation-start-site/ATG_in_5-UTR.bed\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for entry in output:\n",
    "        f.write('\\t'.join(map(str, entry)) + '\\n')\n",
    "\n",
    "print(f\"Updated data written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
